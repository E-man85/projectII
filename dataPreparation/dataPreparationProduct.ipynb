{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation Product File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 699 entries, 0 to 698\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   product_id      699 non-null    object \n",
      " 1   product_length  681 non-null    float64\n",
      " 2   product_depth   683 non-null    float64\n",
      " 3   product_width   683 non-null    float64\n",
      " 4   cluster_id      649 non-null    object \n",
      " 5   hierarchy1_id   699 non-null    object \n",
      " 6   hierarchy2_id   699 non-null    object \n",
      " 7   hierarchy3_id   699 non-null    object \n",
      " 8   hierarchy4_id   699 non-null    object \n",
      " 9   hierarchy5_id   699 non-null    object \n",
      "dtypes: float64(3), object(7)\n",
      "memory usage: 54.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Carregar ficheiro\n",
    "import pandas as pd\n",
    "product = pd.read_csv(r\"C:\\Users\\Egomes\\Desktop\\PG_Analytics_Data_science_empresarial\\Isla_gaia\\14-ProjetoII\\projetoII\\rawData\\product.csv\")\n",
    "product.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preencher NaN da Coluna cluster_id\n",
    "\n",
    "### Uso de RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numero de registos  NaN da coluna cluster_id\n",
    "len(product[product['cluster_id'].isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "data_select = product.copy()\n",
    "# considerar colunas hierarchy\n",
    "data_select = data_select[data_select.columns[4:]] \n",
    "# tranformar colunas em variáveis binárias\n",
    "data_encoded = pd.get_dummies(data_select, columns=['hierarchy1_id','hierarchy2_id','hierarchy3_id','hierarchy4_id','hierarchy5_id'])\n",
    "\n",
    "# Dividir o DataFrame em conjunto de treinamento e conjunto de teste\n",
    "train_data = data_encoded.dropna()\n",
    "test_data = data_encoded[data_encoded['cluster_id'].isnull()]\n",
    "\n",
    "# Criar um dicionário de mapeamento para os rótulos\n",
    "label_mapping = {label: i for i, label in enumerate(train_data['cluster_id'].unique())}\n",
    "\n",
    "# Mapear os rótulos nos dados de treinamento e teste\n",
    "train_data_m = train_data.copy()\n",
    "train_data_m['label'] = train_data['cluster_id'].map(label_mapping)\n",
    "\n",
    "# Obter as features e o target para treinar o modelo\n",
    "features = train_data_m.columns[1:-1]\n",
    "target = 'label'\n",
    "\n",
    "# Treinar modelo de classificação\n",
    "model = RandomForestClassifier()\n",
    "model.fit(train_data_m[features], train_data_m[target])\n",
    "\n",
    "# Prever os rótulos para os dados de teste\n",
    "predicted_labels = model.predict(test_data[features])\n",
    "\n",
    "test_data_label = test_data.copy()\n",
    "test_data_label.loc[:, 'predicted_cluster_id'] = predicted_labels\n",
    "\n",
    "# variáveis categoricas em coluna no dataframe\n",
    "reverse_label_mapping = {value: key for key, value in label_mapping.items()}\n",
    "test_data_label.loc[:, 'predicted_cluster_id'] = test_data_label['predicted_cluster_id'].map(reverse_label_mapping)\n",
    "test_data_label= test_data_label['predicted_cluster_id']\n",
    "\n",
    "data_select1 = product.copy()\n",
    "data_select1.loc[test_data_label.index, \"cluster_id\"] = test_data_label.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 699 entries, 0 to 698\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   product_id      699 non-null    object \n",
      " 1   product_length  681 non-null    float64\n",
      " 2   product_depth   683 non-null    float64\n",
      " 3   product_width   683 non-null    float64\n",
      " 4   cluster_id      699 non-null    object \n",
      " 5   hierarchy1_id   699 non-null    object \n",
      " 6   hierarchy2_id   699 non-null    object \n",
      " 7   hierarchy3_id   699 non-null    object \n",
      " 8   hierarchy4_id   699 non-null    object \n",
      " 9   hierarchy5_id   699 non-null    object \n",
      "dtypes: float64(3), object(7)\n",
      "memory usage: 54.7+ KB\n"
     ]
    }
   ],
   "source": [
    "product1 = data_select1.copy()\n",
    "product1.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preencher NaN da Coluna product_width\n",
    "\n",
    "### Uso de RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numero de registos  NaN da coluna product_width\n",
    "len(product1[product1['product_width'].isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "data_select = product1.copy()\n",
    "# considerar colunas hierarchy\n",
    "data_select = data_select[data_select.columns[3:5]] \n",
    "# tranformar colunas em variáveis binárias\n",
    "data_encoded = pd.get_dummies(data_select, columns=['cluster_id'])\n",
    "\n",
    "# Dividir o DataFrame em conjunto de treinamento e conjunto de teste\n",
    "train_data = data_encoded.dropna()\n",
    "test_data = data_encoded[data_encoded['product_width'].isnull()]\n",
    "\n",
    "# Separar os recursos (features) e o alvo (target)\n",
    "X = train_data.drop(['product_width'], axis=1)\n",
    "y = train_data['product_width']\n",
    "X_test = test_data.drop(['product_width'], axis=1)\n",
    "\n",
    "# Criar o modelo de regressão com RandomForestRegressor\n",
    "model = RandomForestRegressor()\n",
    "# Treinar o modelo com os dados de treinamento\n",
    "model.fit(X, y)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "y_pred = model.predict(X_test)\n",
    "import numpy as np\n",
    "data_select1 = product1.copy()\n",
    "# Identificar os índices dos NaN\n",
    "nan_indices = np.isnan(data_select1['product_width'])\n",
    "# Substituir os NaN com os valores do array\n",
    "data_select1.loc[nan_indices, 'product_width'] = y_pred[:nan_indices.sum()]\n",
    "data_select1['product_width'] = data_select1['product_width'].round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 699 entries, 0 to 698\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   product_id      699 non-null    object \n",
      " 1   product_length  681 non-null    float64\n",
      " 2   product_depth   683 non-null    float64\n",
      " 3   product_width   699 non-null    float64\n",
      " 4   cluster_id      699 non-null    object \n",
      " 5   hierarchy1_id   699 non-null    object \n",
      " 6   hierarchy2_id   699 non-null    object \n",
      " 7   hierarchy3_id   699 non-null    object \n",
      " 8   hierarchy4_id   699 non-null    object \n",
      " 9   hierarchy5_id   699 non-null    object \n",
      "dtypes: float64(3), object(7)\n",
      "memory usage: 54.7+ KB\n"
     ]
    }
   ],
   "source": [
    "product2 = data_select1.copy()\n",
    "\n",
    "product2.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preencher NaN da Coluna product_depth \n",
    "\n",
    "### Uso de RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numero de registos  NaN da coluna product_width\n",
    "len(product2[product2['product_depth'].isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "data_select = product2.copy()\n",
    "# considerar colunas hierarchy\n",
    "data_select = data_select[data_select.columns[2:5]] \n",
    "# tranformar colunas em variáveis binárias\n",
    "data_encoded = pd.get_dummies(data_select, columns=['cluster_id'])\n",
    "\n",
    "# Dividir o DataFrame em conjunto de treinamento e conjunto de teste\n",
    "train_data = data_encoded.dropna()\n",
    "test_data = data_encoded[data_encoded['product_depth'].isnull()]\n",
    "\n",
    "# Separar os recursos (features) e o alvo (target)\n",
    "X = train_data.drop(['product_depth'], axis=1)\n",
    "y = train_data['product_depth']\n",
    "X_test = test_data.drop(['product_depth'], axis=1)\n",
    "\n",
    "# Criar o modelo de regressão com RandomForestRegressor\n",
    "model = RandomForestRegressor()\n",
    "# Treinar o modelo com os dados de treinamento\n",
    "model.fit(X, y)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "y_pred = model.predict(X_test)\n",
    "import numpy as np\n",
    "data_select1 = product2.copy()\n",
    "# Identificar os índices dos NaN\n",
    "nan_indices = np.isnan(data_select1['product_depth'])\n",
    "# Substituir os NaN com os valores do array\n",
    "data_select1.loc[nan_indices, 'product_depth'] = y_pred[:nan_indices.sum()]\n",
    "data_select1['product_depth'] = data_select1['product_depth'].round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 699 entries, 0 to 698\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   product_id      699 non-null    object \n",
      " 1   product_length  681 non-null    float64\n",
      " 2   product_depth   699 non-null    float64\n",
      " 3   product_width   699 non-null    float64\n",
      " 4   cluster_id      699 non-null    object \n",
      " 5   hierarchy1_id   699 non-null    object \n",
      " 6   hierarchy2_id   699 non-null    object \n",
      " 7   hierarchy3_id   699 non-null    object \n",
      " 8   hierarchy4_id   699 non-null    object \n",
      " 9   hierarchy5_id   699 non-null    object \n",
      "dtypes: float64(3), object(7)\n",
      "memory usage: 54.7+ KB\n"
     ]
    }
   ],
   "source": [
    "product3 = data_select1.copy()\n",
    "\n",
    "product3.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preencher NaN da Coluna product_length\n",
    "\n",
    "### Uso de RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numero de registos  NaN da coluna product_width\n",
    "len(product3[product3['product_length'].isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "data_select = product3.copy()\n",
    "# considerar colunas hierarchy\n",
    "data_select = data_select[data_select.columns[1:5]] \n",
    "# tranformar colunas em variáveis binárias\n",
    "data_encoded = pd.get_dummies(data_select, columns=['cluster_id'])\n",
    "\n",
    "# Dividir o DataFrame em conjunto de treinamento e conjunto de teste\n",
    "train_data = data_encoded.dropna()\n",
    "test_data = data_encoded[data_encoded['product_length'].isnull()]\n",
    "\n",
    "# Separar os recursos (features) e o alvo (target)\n",
    "X = train_data.drop(['product_length'], axis=1)\n",
    "y = train_data['product_length']\n",
    "X_test = test_data.drop(['product_length'], axis=1)\n",
    "\n",
    "# Criar o modelo de regressão com RandomForestRegressor\n",
    "model = RandomForestRegressor()\n",
    "# Treinar o modelo com os dados de treinamento\n",
    "model.fit(X, y)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "y_pred = model.predict(X_test)\n",
    "import numpy as np\n",
    "data_select1 = product3.copy()\n",
    "# Identificar os índices dos NaN\n",
    "nan_indices = np.isnan(data_select1['product_length'])\n",
    "# Substituir os NaN com os valores do array\n",
    "data_select1.loc[nan_indices, 'product_length'] = y_pred[:nan_indices.sum()]\n",
    "data_select1['product_length'] = data_select1['product_length'].round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 699 entries, 0 to 698\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   product_id      699 non-null    object \n",
      " 1   product_length  699 non-null    float64\n",
      " 2   product_depth   699 non-null    float64\n",
      " 3   product_width   699 non-null    float64\n",
      " 4   cluster_id      699 non-null    object \n",
      " 5   hierarchy1_id   699 non-null    object \n",
      " 6   hierarchy2_id   699 non-null    object \n",
      " 7   hierarchy3_id   699 non-null    object \n",
      " 8   hierarchy4_id   699 non-null    object \n",
      " 9   hierarchy5_id   699 non-null    object \n",
      "dtypes: float64(3), object(7)\n",
      "memory usage: 54.7+ KB\n"
     ]
    }
   ],
   "source": [
    "product4 = data_select1.copy()\n",
    "\n",
    "product4.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exportação concluida!\n"
     ]
    }
   ],
   "source": [
    "# criar csv para consulta quando necessário\n",
    "product4.to_csv(r\"C:\\Users\\Egomes\\Desktop\\PG_Analytics_Data_science_empresarial\\Isla_gaia\\14-ProjetoII\\projetoII\\dataStaging\\dimProduct.csv\", index=False)\n",
    "print('EDesk    xportação concluida!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projectII",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
